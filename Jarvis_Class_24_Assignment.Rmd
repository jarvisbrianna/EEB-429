---
title: "Model Building: putting it all together"
author: "Brianna Jarvis"
output:
  html_document: default
  pdf_document: default
language: R
---

<!-- To render the assignment in Rmarkdown, enter the command below in the R console -->
<!-- rmarkdown::render("Class_24_Assignment.Rmd") -->

Save this Rmarkdown script as a file named “YourlastName_Assignment24.Rmd”. 
For each question, fill out the answer and, where requested, 
provide the relevant R code using "```" and the echo = TRUE argument.

When finished, Knit your script together into an html report, 
saved as “YourlastName_Assignment24.html” and upload the 
resulting file to the Canvas site (in today’s class folder) to turn it in. 
It is due before our next class.

\

**This homework assignment will test your abilities to:**

1. think critically and creatively about model building

2. extrapolate from in-class exercises to simulate data and do inference with generalized linear models

3. hone your R skillz: function building, data visualization, etc.

\

### Question 1

Explain in your own words each of the terms in each of the equations below, 
as well as what each equation is doing, and what they are all doing together.

$Y_i \sim \text{Pois}(\lambda_i=f(x_i))$ \

-- $Y_i$ is the observed count for the i-th observation.

-- $Pois(\lambda_i)$ is Poisson distribution with rate parameter $\lambda_i$, gives the **expected number of events**.

-- $f(x_i)$ is a function of the predictor variable $x_i$ used to model $\lambda_i$.

-- altogether, it is an equation for the expected count ($\lambda_i$) dependent on some function of an input variable($x_i$).

$\lambda = \text{exp}(f(x_i))$ \

-- this equation explains how the mean of the Poisson distribution ($\lambda_i$) is computed with the function $f(x_i)$. the mean of a Poisson distribution is an exponential function of a linear predictor. 

-- $exp(f(x_i))$ exponentiates the output of the function to ensure that $\lambda_i > 0$ (required since Poisson rates have to be positive).

$f(x_i) = \alpha + \beta x_i$ \

-- linear deterministic function of the model. how $x_i$ affects the expected count. 

-- $f(x_i)$ is a linear function with predictor variable $x_i$.

-- $\alpha$ is the intercept, the baseline log-rate when $x_i = 0$.

-- $\beta$ is the slope, how the log-rate changes with each unit increase in $x_i$.


-- **all together: you start with a linear model ($f(x_i) = \alpha + \beta x_i$), transform it using the exponential function to get the expected count ($\lambda_i = exp(f(x_i)) = exp(\alpha + \beta x_i)$), and model the observed counts $Y_i$ as Poisson distributed with $Y_i \sim Pois(\lambda_i)$**. 

### Question 2

Write mle2 code blocks for the following models.
For each, define an R function for the inverse link function and 
the deterministic function, and write out the mle2 call 
using a data frame with named columns "predictor" and "response".

```{r}
library(bbmle)
```

A) Binomial regression (sample size of 15)

```{r}
# deterministic function
detFuncBinom <- function(x,a,b){
  return(a + b*x)
}

#inverse link function
invLinkBinom <- function(z){
  return(1/(1+exp(-z)))
}

# simulate data
xBinom <- runif(5e3,0,100)
aBinom <- 4
bBinom <- 0.4
sizeBinom <- 15
yBinom <- rbinom(5e3, size=sizeBinom, 
                 prob=invLinkBinom(detFuncBinom(xBinom,aBinom,bBinom))) 
mydataBinom <- data.frame('predictor'=xBinom,'response'=yBinom)

# define the likelihood 
logLikBinom <- function(a,b){
  prob <- invLinkBinom(detFuncBinom(mydataBinom$predictor, a, b))
  return(-sum(dbinom(mydataBinom$response, size=sizeBinom, prob=prob, log=TRUE)))
}

# infer parameter values used to simulate data
modBinom <- mle2(logLikBinom, start= list(a=1, b=1))

# look at coefficients
modBinom@coef
```

B) Poisson Regression

```{r}
# deterministic function
detFuncPois <- function(x,a,b){
  return(exp(a+b*x)/(1+exp(a+b*x)))
}

#inverse link function
invLinkPois <- function(z){
  return(exp(z))
}

# simulate data
xPois <- runif(5e3,0,100)
aPois <- -5
bPois <- 0.3
yPois <- rpois(5e3, lambda=invLinkPois(detFuncPois(xPois,aPois,bPois)))
mydataPois <- data.frame('predictor'=xPois,'response'=yPois)

# infer parameter values used to simulate data
modPois <- mle2(response ~ dpois(lambda=invLinkPois(
  detFuncPois(predictor,aPois,bPois))),
  data=mydataPois,
  start=list('aPois'=1,'bPois'=1))

# look at coefficients
modPois@coef
```

C) Linear model (aka Normal regression)

```{r}
# define a deterministic function, in this case, a linear function
detFuncNorm <- function(x,a,b){
  return(a + b*x)
}

# define an inverse link function, in this case, the identity
invLinkNorm <- function(z){
  return(z)
}

# simulate data to test on
xNorm <- runif(5e2,0,100)
aNorm <- 1.3
bNorm <- -0.9
sNorm <- 7
yNorm <- rnorm(5e2, mean=invLinkNorm(detFuncNorm(xNorm,aNorm,bNorm)), sd=sNorm)
mydataNorm <- data.frame('predictor'=xNorm, 'response'=yNorm)

# now see if we can infer the parameter values used to simulate ata
modNorm <- mle2(response ~ dnorm(mean=invLinkNorm(
  detFuncNorm(predictor,aNorm,bNorm)),sd=sNorm),
  data=mydataNorm, 
  start=list('aNorm'=1,'bNorm'=1,'sNorm'=1))

#and can look at the coefficients
modNorm@coef
```



### Question 3

Use mle2 to infer the parameters of the model 
I used to simulate the data saved in the "mysteryData.Robj" 
file posted on Canvas.

#### testing a linear Normal Model
```{r}
load("~/Desktop/EEB 429/mysteryData.Robj")
str(mysteryData)
```

```{r}
# normal log-likelihood function for testing
logLikFunc <- function(mu, sigma){
  return(-sum(dnorm(mysteryData$response, mean=mu, sd=sigma, log=TRUE)))
}

# fit using mle2
model <- mle2(logLikFunc, start=list(mu=mean(mysteryData$response), sigma=sd(mysteryData$response)))
summary(model)
```

Plot the line from the model you fit and also 
a histogram of the residuals (the observed data - 
their expected value for all data points).

```{r}
# linear model
model.linear <- lm(response ~ predictor, data=mysteryData)

# plot observed data
plot(mysteryData$predictor, mysteryData$response, main='observed data vs fitted model',
     xlab='predictor', ylab='response', pch=19, col='blue')

# add fitted line
abline(model.linear,col='red')
```

```{r}
# calculate residuals
residuals <- mysteryData$response - fitted(model.linear)

# plot histogram
hist(residuals, main='histogram of residuals', xlab='residuals', col='lightblue', border='black')
```

